YASH VISHE
website.io LinkedIn yvishe@ucsd.edu +91 81046 52268

### EDUCATION

University of California San Diego La Jolla, CA
Master of Science in Data Science Sep. 2024 - Jun. 2026

University of Mumbai Mumbai, India
Bachelor of Engineering in Computer Engineering Aug. 2019 - Jun. 2023

### TECHNICAL SKILLS

**Languages/Tools:** Python, C++, SQL, Tableau, Git, GitLab, AWS, Airflow, Superset, GCP

**Libraries/Frameworks:**  TensorFlow, Keras, Scikit-learn, Pandas, Matplotlib, XGBoost, Flask, SpaCy, NLTK, LangChain, LangGraph, KnowledgeGraphs, ChromaDB

**Skills:**

* **Large-Scale Model Training & AI System Design:** Expertise in designing, implementing, and evaluating large-scale machine learning models and AI systems, leveraging frameworks like TensorFlow and Keras. Proven ability to apply cutting-edge AI techniques and research to real-world problems. 
* **Data Engineering & Analysis:** Proficient in data engineering techniques, including ETL pipeline development using tools like Airflow and AWS Redshift. Skilled in data analysis, visualization (Tableau, Matplotlib), and cleaning, enabling data-driven insights.
* **Natural Language Processing (NLP):** Experienced in NLP techniques, including Named Entity Recognition, text summarization, and document query agent development, utilizing libraries like SpaCy, NLTK, and LangChain. 
* **Communication & Collaboration:**  Effective communicator with strong collaboration skills, demonstrated through successful project leadership and teamwork experience.

### PROFESSIONAL EXPERIENCE

**Media.net Mumbai, India Data Analyst (Python, SQL, AWS Redshift, Airflow, Superset, Tableau) July. 2023 - Aug. 2024**

• Designed and implemented efficient ETL pipelines, migrating 46 alerts from Apache Superset to Apache Airflow to reduce the load on AWS Redshift, resulting in a 38% improvement in data retrieval and analysis speed for both ProdOps and DevOps teams.
• Engineered data solutions by creating and managing various buckets on AWS S3 to facilitate storage and access of CSV files and images for alerts, significantly enhancing data accessibility and storage efficiency.
• Collaborated with senior leadership to analyze one year of data on Tableau, identifying key sources for traffic volume growth and providing actionable insights leading to data-driven decision-making.
• Developed a dynamic bid adjustment algorithm in Python, strategically increasing bids with volume growth and reducing them otherwise, achieving a 13% increase in overall traffic volume, showcasing expertise in data-driven optimization.

**Neumann Fornaxx New Delhi, India Software Development Intern (Python, SQL, HTML, CSS) Nov. 2022 - Feb. 2023**

• Led a team of three interns, demonstrating leadership and teamwork, to successfully deliver a project at Neumann Fornax ahead of schedule.
• Gathered and processed over 100,000 rows of data from Zomato and Swiggy using Python CRONs and BeautifulSoup for data analysis, showcasing proficiency in web scraping and data extraction.
• Designed and implemented an automated system to delete duplicate data, reducing database size by 62%, highlighting skills in data cleaning and optimization for efficient data management.

### PERSONAL PROJECTS

**Document Query Agent using Multi-Modal RAG — Langchain, Python, VertexAI, ChromaDB (GitHub)**
• Designed and implemented a document query agent, showcasing expertise in AI system design using Vertex AI, ChromaDB, and LangChain. 
• Employed multi-modal self-reflective RAG for precise data retrieval and integrated Tavily web search agent to mitigate hallucination issues, demonstrating an understanding of cutting-edge AI techniques.
• Programmed the Gemini-1.5-pro model to generate summaries of unstructured data, highlighting experience in large-scale model training and data enhancement for improved AI system performance.

**Community Analysis using Graph Networks — Python, SpaCy, NetworkX (Github)**
• Developed a system to parse large text data, extracting and analyzing relationships using Named Entity Recognition, showcasing experience with data processing and analysis techniques relevant to large-scale data sets.
• Created interactive network graphs and employed community detection algorithms, demonstrating expertise in data visualization and complex network analysis, valuable skills for understanding and improving AI systems.

**Book Recommendation Engine — Python, NLTK, Sklearn (Github)**
• Designed and implemented a book recommendation system using machine learning algorithms like cosine similarity, TFIdvectorizer, and collaborative filtering.
• Scraped and processed data from GoodReads, showcasing data collection and processing skills relevant to training and improving AI models.
• This project highlights experience in building and optimizing machine learning models, a crucial aspect of large-scale model training and AI system design. 

### RESEARCH AND PUBLICATIONS

**Enhancing Brain Tumor Detection Using Multimodal Approach** | May 2024
*IEEE · International Conference on Artificial Intelligence and Machine Learning Applications*
This research focused on optimizing deep learning models for large-scale medical image analysis, specifically brain tumor detection. I trained and evaluated various architectures, including ResNet50, InceptionNet, and DenseNet, employing techniques like ensemble learning (weighted majority averaging) to achieve high accuracy (96.33%).  Furthermore, I investigated the impact of loss functions, comparing Focal Tversky Loss and Dice Loss, to minimize false negatives.  The project also involved developing a segmentation model (ResUNet) for precise tumor localization within MRI scans.